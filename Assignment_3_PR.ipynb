{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment#3_PR.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "LAJ4mKwHILi2",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Testing for GPU availability\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5uQaU1ZvBPgV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**1-Downloading Dataset**"
      ]
    },
    {
      "metadata": {
        "id": "s_B07ZTYF-WI",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "# Installing database file/s\n",
        "!wget http://104.197.136.14/ds/2016.04/2016.04C.multisnr.pkl.bz2\n",
        "!bzip2 -d 2016.04C.multisnr.pkl.bz2\n",
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PplOSDykBPHt",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "# The classes Sequential and Dense are used to specify the nodes, connections, specifications of the neural network.\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "N9skEKoZBWnZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "extracting data"
      ]
    },
    {
      "metadata": {
        "id": "YrPJO_9avMIQ",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "import pickle\n",
        "import gzip\n",
        "import numpy\n",
        "\n",
        "with open('2016.04C.multisnr.pkl', 'rb') as f:\n",
        "    u = pickle._Unpickler(f)\n",
        "    u.encoding = 'latin1'\n",
        "    p = u.load()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xt55KkVCXkt8",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "#Kareem\n",
        "#alternative method (like paper code)\n",
        "import numpy as np\n",
        "snrs,mods = map(lambda j: sorted(list(set(map(lambda x: x[j], p.keys())))), [1,0])\n",
        "X = []  \n",
        "lbl = []\n",
        "for mod in mods:\n",
        "    for snr in snrs:\n",
        "        X.append(p[(mod,snr)])\n",
        "        for i in range(p[(mod,snr)].shape[0]):  lbl.append((mod,snr))\n",
        "X = np.vstack(X)\n",
        "print(X.shape)\n",
        "print(\"one sample :\")\n",
        "print(X[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "o3_YKUZDrL-i",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "making sense of structure of data:"
      ]
    },
    {
      "metadata": {
        "id": "nvD6VLdpX8_Q",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "#Kareem\n",
        "#all keys\n",
        "print(\"keys:\")\n",
        "print(p.keys())\n",
        "#print(p[\"QPSK\",2].shape)\n",
        "print(\"shape of all data:\")\n",
        "print(X.shape)\n",
        "#list of all shapes:\n",
        "shapes=[]\n",
        "snrs=[]\n",
        "mod_types=[]\n",
        "for x in p.keys():\n",
        "  shapes.append(p[x].shape)\n",
        "  snrs.append(x[1])\n",
        "  mod_types.append(x[0])\n",
        "print(\"same distribution of number of samples as shown:\")\n",
        "print(sorted(shapes)[0:20])\n",
        "print(sorted(shapes)[20:40])\n",
        "print(sorted(shapes)[40:60])\n",
        "\n",
        "print(\"same modulation type but different SNRs:\")\n",
        "print(p[\"QPSK\",-20].shape)\n",
        "print(p[\"QPSK\",-18].shape)\n",
        "print(p[\"QPSK\",-16].shape)\n",
        "print(p[\"QPSK\",-14].shape)\n",
        "print(p[\"QPSK\",-12].shape)\n",
        "print(p[\"QPSK\",-10].shape)\n",
        "print(p[\"QPSK\",-8].shape)\n",
        "print(p[\"QPSK\",-6].shape)\n",
        "print(p[\"QPSK\",-4].shape)\n",
        "print(p[\"QPSK\",-2].shape)\n",
        "print(p[\"QPSK\",0].shape)\n",
        "print(p[\"QPSK\",2].shape)\n",
        "print(p[\"QPSK\",4].shape)\n",
        "print(p[\"QPSK\",6].shape)\n",
        "print(p[\"QPSK\",8].shape)\n",
        "print(p[\"QPSK\",10].shape)\n",
        "print(p[\"QPSK\",12].shape)\n",
        "print(p[\"QPSK\",14].shape)\n",
        "print(p[\"QPSK\",16].shape)\n",
        "print(p[\"QPSK\",18].shape)\n",
        "\n",
        "\n",
        "\n",
        "print(\"Again : same modulation type but different SNRs:\")\n",
        "print(p[\"CPFSK\",-20].shape)\n",
        "print(p[\"CPFSK\",-18].shape)\n",
        "print(p[\"CPFSK\",-16].shape)\n",
        "print(p[\"CPFSK\",-14].shape)\n",
        "print(p[\"CPFSK\",-12].shape)\n",
        "print(p[\"CPFSK\",-10].shape)\n",
        "print(p[\"CPFSK\",-8].shape)\n",
        "print(p[\"CPFSK\",-6].shape)\n",
        "print(p[\"CPFSK\",-4].shape)\n",
        "print(p[\"CPFSK\",-2].shape)\n",
        "print(p[\"CPFSK\",0].shape)\n",
        "print(p[\"CPFSK\",2].shape)\n",
        "print(p[\"CPFSK\",4].shape)\n",
        "print(p[\"CPFSK\",6].shape)\n",
        "print(p[\"CPFSK\",8].shape)\n",
        "print(p[\"CPFSK\",10].shape)\n",
        "print(p[\"CPFSK\",12].shape)\n",
        "print(p[\"CPFSK\",14].shape)\n",
        "print(p[\"CPFSK\",16].shape)\n",
        "print(p[\"CPFSK\",18].shape)\n",
        "\n",
        "print(\"same SNR for Different modulation types:\")\n",
        "print(p[\"QPSK\",2].shape)\n",
        "print(p[\"PAM4\",2].shape)\n",
        "print(p[\"AM-DSB\",2].shape)\n",
        "print(p[\"QAM64\",2].shape)\n",
        "print(p[\"AM-SSB\",2].shape)\n",
        "print(p[\"QAM16\",2].shape)\n",
        "print(p[\"8PSK\",2].shape)\n",
        "print(\"values in keys:\")\n",
        "print(sorted(set(snrs)))\n",
        "print(len(set(snrs)))\n",
        "print(set(mod_types))\n",
        "print(len(set(mod_types)))\n",
        "print(\"all different shapes:\")\n",
        "print(sorted(set(shapes)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QkOSFR6MbUDY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Conclusion of dataset structure:\n",
        "\n",
        "Dataset has 11 modulation types and 20 SNR values forming 220 different keys\n",
        "each key has different number of samples\n",
        "\n",
        "each Modulation type (ex : QPSK,8PSK ...etc) has same number of samples for different SNRs\n",
        "\n",
        "the 128 dimentions represent values at each micro second of 128 micro seconds so these are samples in time\n",
        "\n",
        "drivative is the slope of a straight line and measures change of y with change of x so I think it is just the difference between each two consecutive sample values (over change of x which is 1)\n",
        "\n",
        "for real valued vectors the drivative is called the gradient (there is a function in numpy for that)\n",
        "\n",
        "numpy's diff does the job also very well (as far as I know) we need only difference between dimentions and divided by change in time which is 1 so only difference is needed\n"
      ]
    },
    {
      "metadata": {
        "id": "p07dhhmSQC1C",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#drivative\n",
        "import numpy as np\n",
        "X_npArray=np.array(X)\n",
        "print(\"before differentiation (2nd sample):\")\n",
        "print(X_npArray[0])\n",
        "print(\"After diffrentiation : (you can see 1st element of any channel is diffrence between 1st and second of array before)\")\n",
        "X_driv=np.diff(X_npArray)\n",
        "print(X_driv[0])\n",
        "z=np.zeros((162060,2,1))\n",
        "print(\"shape before:\")\n",
        "print(X_driv.shape)\n",
        "X_driv=np.concatenate((z, X_driv), axis=2)\n",
        "print(\"shape after:\")\n",
        "print(X_driv.shape)\n",
        "print(\"element with added zeros :\")\n",
        "print(X_driv[0])\n",
        "print(X[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "clcHsOoS6Epi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Integration using trapzoidal cummulative integration\n",
        "### setting initial value to zero to make arrays match in size ((127+1,128))"
      ]
    },
    {
      "metadata": {
        "id": "mkGkQ1_VhhPe",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy import integrate\n",
        "\n",
        "X_npArray=np.array(X)\n",
        "#############################################\n",
        "S=integrate.cumtrapz(X_npArray, initial=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XiOo746posgI",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#add dimention of zeros\n",
        "\n",
        "X_play=X_driv\n",
        "y=np.zeros((162060,2,1))\n",
        "z=np.concatenate((y, X_play), axis=2)\n",
        "print(z.shape)\n",
        "print(z)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NIAt3FIthIdI",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "combined_Data=np.zeros((162060,6,128))\n",
        "print(combined_Data.shape)\n",
        "for (i) in range(len(combined_Data)):\n",
        "    combined_Data[i]=np.vstack((X[i],X_driv[i],S[i]))\n",
        "print(combined_Data[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LE032gi2gGao",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "2 dimentions vectors because complex values a vector for real value and imaginary value"
      ]
    },
    {
      "metadata": {
        "id": "jZHqyJehCZSc",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Making the Confusion Matrix\n",
        "# from sklearn.metrics import confusion_matrix\n",
        "# cm = confusion_matrix(..., ...) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "O14V_gyOgFfv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**The actual Network**"
      ]
    },
    {
      "metadata": {
        "id": "_p7RQ92TgKQ7",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install keras \n",
        "!pip install tflearn\n",
        "!pip install tensor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PCEWEKbXBwDP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "loading samples from pickle file"
      ]
    },
    {
      "metadata": {
        "id": "LwOYxVkigU_4",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import os,random\n",
        "#os.environ[\"KERAS_BACKEND\"] = \"theano\"\n",
        "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
        "#os.environ[\"THEANO_FLAGS\"]  = \"device=cuda,floatX=float32\"\n",
        "import numpy as np\n",
        "from keras.utils import np_utils\n",
        "import keras.models as models\n",
        "from keras.layers.core import Reshape,Dense,Dropout,Activation,Flatten\n",
        "from keras.layers.noise import GaussianNoise\n",
        "from keras.layers.convolutional import Conv2D, MaxPooling2D, ZeroPadding2D\n",
        "from keras.regularizers import *\n",
        "from keras.optimizers import adam\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pickle, random, sys, keras\n",
        "# Installing database file/s\n",
        "!wget http://104.197.136.14/ds/2016.04/2016.04C.multisnr.pkl.bz2\n",
        "!bzip2 -d 2016.04C.multisnr.pkl.bz2\n",
        "!ls\n",
        "# The classes Sequential and Dense are used to specify the nodes, connections, specifications of the neural network.\n",
        "\n",
        "with open('2016.04C.multisnr.pkl', 'rb') as f:\n",
        "    u = pickle._Unpickler(f)\n",
        "    u.encoding = 'latin1'\n",
        "    Xd = u.load()\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ja9BZlu9gVws",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "snrs,mods = map(lambda j: sorted(list(set(map(lambda x: x[j], Xd.keys())))), [1,0])\n",
        "X = []  \n",
        "lbl = []\n",
        "for mod in mods:\n",
        "    for snr in snrs:\n",
        "        X.append(Xd[(mod,snr)])\n",
        "        for i in range(Xd[(mod,snr)].shape[0]):  lbl.append((mod,snr))\n",
        "X = np.vstack(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "npJTCCr3B3si",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "diffrentiation"
      ]
    },
    {
      "metadata": {
        "id": "uRBLHasBmF6o",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#Kareem trying accuracy for differentiated data, uncomment the cell to see results\n",
        "'''\n",
        "import numpy as np\n",
        "X_npArray=np.array(X)\n",
        "\n",
        "X=np.diff(X_npArray)\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NRjhBaexB682",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "dividing data into training and testing sets"
      ]
    },
    {
      "metadata": {
        "id": "kT96O6cVgaNS",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Partition the data\n",
        "#  into training and test sets of the form we can train/test on \n",
        "#  while keeping SNR and Mod labels handy for each\n",
        "np.random.seed(2016)\n",
        "n_examples = X.shape[0]\n",
        "n_train = n_examples * 0.5\n",
        "train_idx = np.random.choice(range(0,n_examples), size= int(n_train), replace=False)\n",
        "test_idx = list(set(range(0,n_examples))-set(train_idx))\n",
        "#changed from x to combined data\n",
        "#X_train = combined_Data[train_idx]\n",
        "#X_test =  combined_Data[test_idx]\n",
        "X_train = X[train_idx]\n",
        "X_test =  X[test_idx]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "R9KhUMBKB_Vx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "one hot encoding for multiclass classification since there are 11 classes (11 modulation techniques)"
      ]
    },
    {
      "metadata": {
        "id": "hHfNwrX1ge4-",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def to_onehot(yy):\n",
        "    yy1 = np.zeros([len(yy), max(yy)+1])\n",
        "    yy1[np.arange(len(yy)),yy] = 1\n",
        "    return yy1 \n",
        "Y_train = to_onehot(list(map(lambda x: mods.index(lbl[x][0]), train_idx)))\n",
        "Y_test = to_onehot(list(map(lambda x: mods.index(lbl[x][0]), test_idx)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "q15B47LIgg_o",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "in_shp = list(X_train.shape[1:])\n",
        "print (X_train.shape, in_shp)\n",
        "classes = mods"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9mY2wTtkCNjN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "parameters and structure of network"
      ]
    },
    {
      "metadata": {
        "id": "hobcHw7TgmcM",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Set up some params \n",
        "nb_epoch = 100    # number of epochs to train on\n",
        "batch_size = 700  # training batch size"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2iS7hoZpRBNK",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#fully connected neural network\n",
        "dr = 0.1\n",
        "model1 = keras.models.Sequential()\n",
        "model1.add(Reshape(in_shp+[1], input_shape=in_shp))\n",
        "model1.add(Dropout(dr))\n",
        "model1.add(Flatten())\n",
        "model1.add(Dense(128, activation='relu', kernel_initializer='he_normal', name=\"dense1\"))\n",
        "model1.add(Dropout(dr))\n",
        "model1.add(Dense(128, activation='relu', kernel_initializer='he_normal', name=\"dense2\"))\n",
        "model1.add(Dropout(dr))\n",
        "model1.add(Dense(64, activation='relu', kernel_initializer='he_normal', name=\"dense3\"))\n",
        "model1.add(Dropout(dr))\n",
        "model1.add(Dense(64, activation='relu', kernel_initializer='he_normal', name=\"dense4\"))\n",
        "model1.add(Dropout(dr))\n",
        "model1.add(Dense( len(classes), kernel_initializer='he_normal', name=\"dense5\" ))\n",
        "model1.add(Activation('softmax'))\n",
        "model1.add(Reshape([len(classes)]))\n",
        "model1.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model1.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PhxqLo8sRG55",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# perform training ...\n",
        "#   - call the main training loop in keras for our network+dataset\n",
        "filepath = 'convmodrecnets_CNN2_0.5.wts.h5'\n",
        "history=model1.fit(X_train,\n",
        "    Y_train,\n",
        "    batch_size=batch_size,\n",
        "    epochs=nb_epoch,\n",
        "    verbose=2,\n",
        "     validation_split=0.05,\n",
        "    callbacks = [\n",
        "        keras.callbacks.ModelCheckpoint(filepath, monitor='val_loss', verbose=0, save_best_only=True, mode='auto'),\n",
        "        keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=0, mode='auto')\n",
        "    ])\n",
        "# we re-load the best weights once training is finished\n",
        "model1.load_weights(filepath)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "s4F9QjG-RJxv",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "score = model1.evaluate(X_test, Y_test, batch_size=batch_size)\n",
        "print(model1.metrics_names)\n",
        "print (score)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jJD13mnmghgf",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import keras.models as models\n",
        "# Build VT-CNN2 Neural Net model using Keras primitives -- \n",
        "#  - Reshape [N,2,128] to [N,1,2,128] on input\n",
        "#  - Pass through 2 2DConv/ReLu layers\n",
        "#  - Pass through 2 Dense layers (ReLu and Softmax)\n",
        "#  - Perform categorical cross entropy optimization\n",
        " \n",
        "dr = 0.1 # dropout rate (%)\n",
        "model = keras.models.Sequential()\n",
        "model.add(Reshape(in_shp+[1], input_shape=in_shp))\n",
        "model.add(ZeroPadding2D((0, 2)))\n",
        "model.add(Conv2D(64, (1, 3),padding='valid', activation=\"relu\", name=\"conv1\",kernel_initializer='glorot_uniform',data_format=\"channels_last\"))\n",
        "model.add(Dropout(dr))\n",
        "model.add(ZeroPadding2D((0, 2)))\n",
        "model.add(Conv2D(16,(2, 3), padding='valid', activation=\"relu\", name=\"conv2\", kernel_initializer='glorot_uniform',data_format=\"channels_last\"))\n",
        "model.add(Dropout(dr))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256, activation='relu', kernel_initializer='he_normal', name=\"dense1\"))\n",
        "model.add(Dropout(dr))\n",
        "model.add(Dense( len(classes), kernel_initializer='he_normal', name=\"dense2\" ))\n",
        "model.add(Activation('softmax'))\n",
        "model.add(Reshape([len(classes)]))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1fEW0N2sCkwS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "training the model :"
      ]
    },
    {
      "metadata": {
        "id": "mQXjSaLshF2E",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# perform training ...\n",
        "#   - call the main training loop in keras for our network+dataset\n",
        "filepath = 'convmodrecnets_CNN2_0.5.wts.h5'\n",
        "model.fit(X_train,\n",
        "    Y_train,\n",
        "    batch_size=batch_size,\n",
        "    epochs=nb_epoch,\n",
        "    verbose=2,\n",
        "     validation_split=0.05,\n",
        "    callbacks = [\n",
        "        keras.callbacks.ModelCheckpoint(filepath, monitor='val_loss', verbose=0, save_best_only=True, mode='auto'),\n",
        "        keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, verbose=0, mode='auto')\n",
        "    ])\n",
        "# we re-load the best weights once training is finished\n",
        "model.load_weights(filepath)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yKqy5_x9Crj5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "testing the model:"
      ]
    },
    {
      "metadata": {
        "id": "mWCqvPjFiIEf",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "scscore = model.evaluate(X_test, Y_test, batch_size=batch_size)\n",
        "print(model.metrics_names)\n",
        "print (scscore)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bxjkTgUQCu1u",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "visuals :"
      ]
    },
    {
      "metadata": {
        "id": "F_B4YrQQRQmS",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Show loss curves \n",
        "plt.figure()\n",
        "plt.title('Training performance')\n",
        "plt.plot(history.epoch, history.history['loss'], label='train loss+error')\n",
        "plt.plot(history.epoch, history.history['val_loss'], label='val_error')\n",
        "plt.legend()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mZwWcs_RRS4X",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def plot_confusion_matrix(cm, title='Confusion matrix', cmap=plt.cm.Blues, labels=[]):\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(labels))\n",
        "    plt.xticks(tick_marks, labels, rotation=45)\n",
        "    plt.yticks(tick_marks, labels)\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pb0T6gtIRTSb",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Plot confusion matrix\n",
        "test_Y_hat = model.predict(X_test, batch_size=batch_size)\n",
        "conf = np.zeros([len(classes),len(classes)])\n",
        "confnorm = np.zeros([len(classes),len(classes)])\n",
        "for i in range(0,X_test.shape[0]):\n",
        "    j = list(Y_test[i,:]).index(1)\n",
        "    k = int(np.argmax(test_Y_hat[i,:]))\n",
        "    conf[j,k] = conf[j,k] + 1\n",
        "for i in range(0,len(classes)):\n",
        "    confnorm[i,:] = conf[i,:] / np.sum(conf[i,:])\n",
        "plot_confusion_matrix(confnorm, labels=classes)\n",
        "# on the right its a color chart to indicate that the darker the color the easier and thee most to identify"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Oil19POdRWb8",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Plot confusion matrix\n",
        "acc = {}\n",
        "for snr in snrs:\n",
        "\n",
        "    # extract classes @ SNR\n",
        "    test_SNRs = list(map(lambda x: lbl[x][1], test_idx))\n",
        "    test_X_i = X_test[np.where(np.array(test_SNRs)==snr)]\n",
        "    test_Y_i = Y_test[np.where(np.array(test_SNRs)==snr)]    \n",
        "\n",
        "    # estimate classes\n",
        "    test_Y_i_hat = model.predict(test_X_i)\n",
        "    conf = np.zeros([len(classes),len(classes)])\n",
        "    confnorm = np.zeros([len(classes),len(classes)])\n",
        "    for i in range(0,test_X_i.shape[0]):\n",
        "        j = list(test_Y_i[i,:]).index(1)\n",
        "        k = int(np.argmax(test_Y_i_hat[i,:]))\n",
        "        conf[j,k] = conf[j,k] + 1\n",
        "    for i in range(0,len(classes)):\n",
        "        confnorm[i,:] = conf[i,:] / np.sum(conf[i,:])\n",
        "    plt.figure()\n",
        "    plot_confusion_matrix(confnorm, labels=classes, title=\"ConvNet Confusion Matrix (SNR=%d)\"%(snr))\n",
        "    \n",
        "    cor = np.sum(np.diag(conf))\n",
        "    ncor = np.sum(conf) - cor\n",
        "    print (\"Overall Accuracy: \", cor / (cor+ncor))\n",
        "    acc[snr] = 1.0*cor/(cor+ncor)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "z1HrPs2cRdII",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Plot accuracy curve\n",
        "plt.plot(snrs, list(map(lambda x: acc[x], snrs)))\n",
        "plt.xlabel(\"Signal to Noise Ratio\")\n",
        "plt.ylabel(\"Classification Accuracy\")\n",
        "plt.title(\"CNN2 Classification Accuracy on RadioML 2016.10 Alpha\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}